{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "import json\n",
    "import urllib\n",
    "from torchvision.transforms import Compose, Lambda, Resize\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    UniformCropVideo\n",
    ") \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 32\n",
    "sampling_rate = 1\n",
    "frames_per_second = 30\n",
    "slowfast_alpha = 4\n",
    "num_clips = 10\n",
    "num_crops = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aff85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\n",
    "model.blocks[6].proj = nn.Linear(2304, 3)\n",
    "model.load_state_dict(torch.load(\"./slowfast_base.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file,device,transform=None, train=True):\n",
    "        super().__init__()\n",
    "        self.file = file\n",
    "        self.len = len(self.file)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.datalayer = PackPathway()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train :\n",
    "            path = self.file[idx][0]\n",
    "            label = self.file[idx][1]\n",
    "            video = EncodedVideo.from_path(path)\n",
    "            video_data = video.get_clip(start_sec=0, end_sec=int(video.duration))\n",
    "            try:\n",
    "                video_data = self.transform(video_data)\n",
    "                inputs = video_data[\"video\"]\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "            except:\n",
    "                inputs = [torch.zeros((3, 8, 256, 256)), torch.zeros((3, 32, 256, 256))]\n",
    "                inputs[0][0][0][0][0] = 100\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "            \n",
    "            return inputs, label\n",
    "        else :\n",
    "            path = self.file[idx][0]\n",
    "            label = self.file[idx][1]\n",
    "            video = EncodedVideo.from_path(path)\n",
    "            video_data = video.get_clip(start_sec=0, end_sec=int(video.duration))\n",
    "            try:\n",
    "                video_data = self.transform(video_data)\n",
    "                inputs = video_data[\"video\"]\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "            except:\n",
    "                inputs = [torch.zeros((3, 8, 256, 256)), torch.zeros((3, 32, 256, 256))]\n",
    "                inputs[0][0][0][0][0] = 100\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "\n",
    "            return inputs, label\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006dfef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            Resize((side_size, side_size)),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad97dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "assult_path = glob(\"./dataset/assult/*.mp4\")\n",
    "train_assult_path = assult_path[:-213]\n",
    "test_assult_path = assult_path[-213:]\n",
    "\n",
    "swoon_path = glob(\"./dataset/swoon/*.mp4\")\n",
    "train_swoon_path = swoon_path[:int(0.8*len(swoon_path))]\n",
    "test_swoon_path = swoon_path[int(0.8*len(swoon_path)):]\n",
    "\n",
    "normal_path = glob(\"./dataset/normal/*.mp4\")\n",
    "train_normal_path = normal_path[:-213]\n",
    "test_normal_path = normal_path[-213:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4df3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(\n",
    "        nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(\n",
    "        nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                    lr=5e-5, correct_bias=False)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    print(\"Valdidation step\")\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, total=len(dataloader)):\n",
    "            pred = model(X)\n",
    "            y = y.to(device)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "test_data = list()\n",
    "\n",
    "for path in test_normal_path:\n",
    "    test_data.append((path, 0))\n",
    "\n",
    "for path in test_assult_path:\n",
    "    test_data.append((path, 1))\n",
    "\n",
    "for path in test_swoon_path:\n",
    "    test_data.append((path, 2))\n",
    "\n",
    "test_dataset = CustomDataset(test_data,device,transform,train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for epoch in range(1,21) :\n",
    "    # 0 : normal, 1 : assult, 2 : swoon\n",
    "\n",
    "    train_data = list()\n",
    "\n",
    "    for path in random.sample(train_normal_path, 851):\n",
    "        train_data.append((path, 0))\n",
    "\n",
    "    for path in random.sample(train_assult_path, 851):\n",
    "        train_data.append((path, 1))\n",
    "\n",
    "    for path in train_swoon_path:\n",
    "        train_data.append((path, 2))\n",
    "    \n",
    "    \n",
    "    train_dataset = CustomDataset(train_data,device,transform,train=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    print(\"------------TRAIN------------\")\n",
    "    for i, d in tqdm(enumerate(train_loader), total=len(train_loader)): \n",
    "        flag = 1\n",
    "        for j in range(len(d[0][0])):\n",
    "            if d[0][0][j][0][0][0][0] == 100:\n",
    "                flag = 0\n",
    "                break\n",
    "        if flag:\n",
    "            data, label = d\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output,label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        \n",
    "    print(\"EPOCH:\", epoch)\n",
    "    print(\"train_loss:{:.6f}\".format(total_loss/len(train_loader)))\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        test_loop(test_loader, model, criterion)\n",
    "\n",
    "        print(\"Saving model\")\n",
    "        path = \"./slowfast_base.pt\"\n",
    "        torch.save(model.state_dict(), path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBiyongi_pytorch",
   "language": "python",
   "name": "bbiyongi_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
